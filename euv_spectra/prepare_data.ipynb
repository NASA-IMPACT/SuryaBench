{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Append base path.  May need to be modified if the folder structure changes\n",
    "sys.path.append(\"../../HelioFM\")\n",
    "\n",
    "from train_spectformer import get_config\n",
    "from utils.data import build_scalers\n",
    "from datasets.helio import HelioNetCDFDataset\n",
    "import eve_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb649eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./ds_configs/config_resnet_18.yaml\"\n",
    "config = get_config(config_path)\n",
    "scalers = build_scalers(info=config.data.scalers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a02adf",
   "metadata": {},
   "source": [
    "### Preparing Data for Neural Network Training and Testing ###\n",
    "\n",
    "In this section, we demonstrate how to prepare the **training data** ('X_train', 'Y_train') for modeling by extracting the relevant AIA and HMI images (`ts`) and the target EVE spectra (`target`) from the dataset. This process includes parsing temporal slices, reshaping them as input tensors, and storing them for efficient reuse during model training.\n",
    "\n",
    "To prepare **validation data** and **testing data**, a similar approach can be followed. The only required adjustments are:\n",
    "\n",
    "- Set `phase = \"val\"` or `\"test\"` when initializing the dataset\n",
    "- Set `ds_time_column = \"val_time\"` or `\"test_time\"` to ensure the correct timestamp alignment\n",
    "\n",
    "Additionally, the dataset uses a default **time matching tolerance** of `\"6m\"`:\n",
    "\n",
    "```python\n",
    "ds_time_tolerance = \"6m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d907890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For details of the Dataloader parameters and returns, check eve_dataloader.py\n",
    "\n",
    "train_dataset = eve_dataloader.EVEDSDataset(\n",
    "    #### All these lines are required by the parent HelioNetCDFDataset class\n",
    "    index_path=config.data.train_data_path,\n",
    "    time_delta_input_minutes=config.data.time_delta_input_minutes,\n",
    "    time_delta_target_minutes=config.data.time_delta_target_minutes,\n",
    "    n_input_timestamps=config.data.n_input_timestamps,\n",
    "    rollout_steps=config.rollout_steps,\n",
    "    channels=config.data.channels,\n",
    "    drop_hmi_probablity=config.drop_hmi_probablity,\n",
    "    num_mask_aia_channels=config.num_mask_aia_channels,\n",
    "    use_latitude_in_learned_flow=config.use_latitude_in_learned_flow,\n",
    "    scalers=scalers,\n",
    "    phase=\"train\",\n",
    "    #### Put your donwnstream (DS) specific parameters below this line\n",
    "    ds_eve_index_path= \"../../hfmds/data/AIA_EVE_dataset_combined.nc\",\n",
    "    ds_time_column=\"train_time\",\n",
    "    ds_time_tolerance = \"6m\",\n",
    "    ds_match_direction = \"forward\"    \n",
    ")\n",
    "\n",
    "print(\"Sample Size:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd581d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Configuration\n",
    "# ===============================\n",
    "\n",
    "X_TRAIN_FILE = \"X_train.pt\" \n",
    "# Since X_train is N samples of 13 channels each having 4k x 4k images,\n",
    "# It should be saved as a torch tensor.\n",
    "\n",
    "Y_TRAIN_FILE = \"Y_train.csv\"\n",
    "# Y_train is N samples of spectra having 1343 wavelength bins\n",
    "\n",
    "# ===============================\n",
    "# Initialize storage lists\n",
    "# ===============================\n",
    "X_list = []  # For input tensors (ts[:, 0, :, :])\n",
    "Y_list = []  # For target tensors (spectra)\n",
    "\n",
    "# ===============================\n",
    "# Loop over the dataset\n",
    "# ===============================\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    # Load the i-th sample from the dataset\n",
    "    item, _ = train_dataset[i]\n",
    "    \n",
    "    # ---------------------------------------\n",
    "    # Input tensor: item['ts'] is shape (13, 2, 4096, 4096)\n",
    "    # We use only the first time slice on axis 1 â†’ ts[:, 0, :, :]\n",
    "    # Resulting shape: (13, 4096, 4096)\n",
    "    # ---------------------------------------\n",
    "    ts = item['ts']\n",
    "    ts_single = ts[:, 0, :, :]  # Extract time slice 0 for all channels\n",
    "\n",
    "    # Ensure it's a PyTorch tensor\n",
    "    ts_tensor = torch.tensor(ts_single) if not isinstance(ts_single, torch.Tensor) else ts_single\n",
    "    X_list.append(ts_tensor)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Output tensor: item['target'] is shape (1343,)\n",
    "    # ---------------------------------------\n",
    "    spectra = item['target']\n",
    "    spectra_tensor = torch.tensor(spectra) if not isinstance(spectra, torch.Tensor) else spectra\n",
    "    Y_list.append(spectra_tensor)\n",
    "\n",
    "    print(f\"Sample {i} loaded\")\n",
    "\n",
    "# ===============================\n",
    "# Stack into single tensors\n",
    "# ===============================\n",
    "X_train = torch.stack(X_list)  # Final shape: (N, 13, 4096, 4096)\n",
    "Y_train = torch.stack(Y_list)  # Final shape: (N, 1343)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "\n",
    "# ===============================\n",
    "# OPTIONAL: Save tensors to disk\n",
    "# ===============================\n",
    "# torch.save(X_train, X_TRAIN_FILE)\n",
    "\n",
    "# df_y = pd.DataFrame(Y_train.cpu().numpy())\n",
    "# df_y.to_csv(\"Y_train.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
